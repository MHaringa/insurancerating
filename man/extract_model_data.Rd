% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_get_data.R
\name{extract_model_data}
\alias{extract_model_data}
\alias{model_data}
\title{Extract model data}
\usage{
extract_model_data(x)

model_data(x)
}
\arguments{
\item{x}{An object of class \code{"glm"}, \code{"refitsmooth"}, or \code{"refitrestricted"}.}
}
\value{
A \code{data.frame} of class \code{"model_data"}, containing the cleaned model
data with additional attributes:
\itemize{
\item \code{rf} — names of risk factors in the model
\item \code{offweights} — weights or offsets if present
\item \code{mgd_rst}, \code{mgd_smt} — merged restrictions/smooths (refit objects only)
\item \code{new_nm}, \code{old_nm} — new and old column names (refit objects only)
}
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}

\code{extract_model_data()} retrieves underlying data from fitted models. It works
for objects of class \code{"glm"}, as well as objects produced by refitting
procedures (\code{"refitsmooth"} or \code{"refitrestricted"}).

The wrapper \code{\link[=model_data]{model_data()}} is deprecated as of version 0.8.0; please use
\code{\link[=extract_model_data]{extract_model_data()}} instead.
}
\details{
For GLM objects, the function:
\itemize{
\item returns the original data used in the model,
\item attaches attributes with the relevant rating factors and any weights/offsets.
}

For refit objects, the function:
\itemize{
\item strips out auxiliary columns used for smoothing/restrictions,
\item attaches attributes with information about rating factors, merged smooths,
restrictions, and offsets.
}
}
\examples{
\dontrun{
library(insurancerating)
library(dplyr)

# Fit GAM for claim frequency
age_policyholder_frequency <- riskfactor_gam(data = MTPL,
                                             nclaims = "nclaims",
                                             x = "age_policyholder",
                                             exposure = "exposure")

# Determine clusters
clusters_freq <- construct_tariff_classes(age_policyholder_frequency)

# Add clusters to MTPL portfolio
dat <- MTPL |>
mutate(age_policyholder_freq_cat = clusters_freq$tariff_classes) |>
mutate(across(where(is.character), as.factor)) |>
mutate(across(where(is.factor), ~biggest_reference(., exposure)))

# Fit frequency and severity model
freq <- glm(nclaims ~ bm + age_policyholder_freq_cat, offset = log(exposure),
            family = poisson(), data = dat)
sev <- glm(amount ~ bm + zip, weights = nclaims,
           family = Gamma(link = "log"), data = dat |> filter(amount > 0))

# Add predictions for freq and sev to data, and calculate premium
premium_df <- dat |>
add_prediction(freq, sev) |>
mutate(premium = pred_nclaims_freq * pred_amount_sev)

# Fit unrestricted model
burn_unrestricted <- glm(premium ~ zip + bm + age_policyholder_freq_cat,
weights = exposure, family = Gamma(link = "log"), data = premium_df)

# Impose smoothing and refit model
burn_restricted <- burn_unrestricted |>
add_smoothing(x_cut = "age_policyholder_freq_cat",
x_org = "age_policyholder",
breaks = seq(18, 95, 5)) |>
refit_glm()

# Extract model data
extract_model_data(burn_restricted)
}

}
\author{
Martin Haringa
}
